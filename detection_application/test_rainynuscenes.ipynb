{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_181219/3804334894.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RainyNuScenes\n",
      "Mean Precision: 0.7755\n",
      "Mean Recall: 0.6762\n",
      "Mean IoU: 0.5311\n",
      "Mean Dice: 0.6697\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define Precision and Recall functions\n",
    "def calculate_precision(pred, target):\n",
    "    true_positive = torch.sum(pred * target)\n",
    "    predicted_positive = torch.sum(pred)\n",
    "    return (true_positive + 1e-6) / (predicted_positive + 1e-6)\n",
    "\n",
    "def calculate_recall(pred, target):\n",
    "    true_positive = torch.sum(pred * target)\n",
    "    actual_positive = torch.sum(target)\n",
    "    return (true_positive + 1e-6) / (actual_positive + 1e-6)\n",
    "\n",
    "# IoU and Dice coefficient functions\n",
    "def calculate_iou(pred, target):\n",
    "    intersection = torch.sum(pred * target)\n",
    "    union = torch.sum(pred) + torch.sum(target) - intersection\n",
    "    return (intersection + 1e-6) / (union + 1e-6)\n",
    "\n",
    "def calculate_dice(pred, target):\n",
    "    intersection = torch.sum(pred * target)\n",
    "    return (2 * intersection + 1e-6) / (torch.sum(pred) + torch.sum(target) + 1e-6)\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_img_path, test_mask_path):\n",
    "    model.eval()\n",
    "\n",
    "    # Transform for test images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((640, 640)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    image_names = sorted(os.listdir(test_img_path))\n",
    "    mask_names = sorted(os.listdir(test_mask_path))\n",
    "\n",
    "    precision_list, recall_list, iou_list, dice_list = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_name, mask_name in zip(image_names, mask_names):\n",
    "            # Load image and mask\n",
    "            img_path = os.path.join(test_img_path, img_name)\n",
    "            mask_path = os.path.join(test_mask_path, mask_name)\n",
    "\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "            image = transform(image).unsqueeze(0).to(device)\n",
    "            mask = transforms.ToTensor()(mask).to(device)\n",
    "            mask = torch.where(mask > 0, torch.tensor(1.0).to(device), torch.tensor(0.0).to(device))\n",
    "\n",
    "            # Get model prediction\n",
    "            output = model(image)\n",
    "            pred = torch.where(output > 0.5, torch.tensor(1.0).to(device), torch.tensor(0.0).to(device))\n",
    "\n",
    "            # Calculate metrics\n",
    "            precision = calculate_precision(pred, mask).item()\n",
    "            recall = calculate_recall(pred, mask).item()\n",
    "            iou = calculate_iou(pred, mask).item()\n",
    "            dice = calculate_dice(pred, mask).item()\n",
    "\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            iou_list.append(iou)\n",
    "            dice_list.append(dice)\n",
    "\n",
    "    # Calculate mean metrics\n",
    "    mean_precision = np.mean(precision_list)\n",
    "    mean_recall = np.mean(recall_list)\n",
    "    mean_iou = np.mean(iou_list)\n",
    "    mean_dice = np.mean(dice_list)\n",
    "\n",
    "    print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "    print(f\"Mean Recall: {mean_recall:.4f}\")\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"Mean Dice: {mean_dice:.4f}\")\n",
    "\n",
    "    return mean_precision, mean_recall, mean_iou, mean_dice\n",
    "\n",
    "\n",
    "# Define U-Net Model with Pretrained ResNet Encoder\n",
    "class UNetWithResNetEncoder(nn.Module):\n",
    "    def __init__(self, out_channels=1):\n",
    "        super(UNetWithResNetEncoder, self).__init__()\n",
    "\n",
    "        # Pretrained ResNet backbone\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "\n",
    "        # Encoder layers from ResNet\n",
    "        self.enc1 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu)  # First conv block\n",
    "        self.enc2 = nn.Sequential(resnet.layer1)  # ResNet layer 1\n",
    "        self.enc3 = nn.Sequential(resnet.layer2)  # ResNet layer 2\n",
    "        self.enc4 = nn.Sequential(resnet.layer3)  # ResNet layer 3\n",
    "        self.enc5 = nn.Sequential(resnet.layer4)  # ResNet layer 4\n",
    "\n",
    "        # Decoder layers\n",
    "        def up_conv(in_channels, out_channels):\n",
    "            return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            return block\n",
    "\n",
    "        self.upconv4 = up_conv(512, 256)\n",
    "        self.dec4 = conv_block(512, 256)\n",
    "\n",
    "        self.upconv3 = up_conv(256, 128)\n",
    "        self.dec3 = conv_block(256, 128)\n",
    "\n",
    "        self.upconv2 = up_conv(128, 64)\n",
    "        self.dec2 = conv_block(128, 64)\n",
    "\n",
    "        self.upconv1 = up_conv(64, 64)\n",
    "        self.dec1 = conv_block(64 + 64, 64)\n",
    "\n",
    "        # Output layer\n",
    "        self.conv_last = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        enc5 = self.enc5(enc4)\n",
    "\n",
    "        # Decoder\n",
    "        dec4 = self.upconv4(enc5)\n",
    "        dec4 = torch.cat((dec4, self._align_tensor(enc4, dec4)), dim=1)\n",
    "        dec4 = self.dec4(dec4)\n",
    "\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, self._align_tensor(enc3, dec3)), dim=1)\n",
    "        dec3 = self.dec3(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, self._align_tensor(enc2, dec2)), dim=1)\n",
    "        dec2 = self.dec2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, self._align_tensor(enc1, dec1)), dim=1)\n",
    "        dec1 = self.dec1(dec1)\n",
    "\n",
    "        return torch.sigmoid(self.conv_last(dec1))\n",
    "\n",
    "    def _align_tensor(self, enc, dec):\n",
    "        \"\"\"Align encoder tensor to match the size of the decoder tensor.\"\"\"\n",
    "        enc_h, enc_w = enc.size(2), enc.size(3)\n",
    "        dec_h, dec_w = dec.size(2), dec.size(3)\n",
    "\n",
    "        if enc_h != dec_h or enc_w != dec_w:\n",
    "            enc = nn.functional.interpolate(enc, size=(dec_h, dec_w), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return enc\n",
    "\n",
    "\n",
    "# Paths to test images and masks\n",
    "test_img_path = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/data/rainyNuScenes/dataset_split/train/images'\n",
    "test_mask_path = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/data/rainyNuScenes/dataset_split/train/labels'\n",
    "save_path = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/rainy_nuscenes_model.pth'\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = UNetWithResNetEncoder(out_channels=1).to(device)\n",
    "model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"RainyNuScenes\")\n",
    "mean_precision, mean_recall, mean_iou, mean_dice = evaluate_model(model, test_img_path, test_mask_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181219/2581559796.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WoodScape\n",
      "Mean Precision: 0.8501\n",
      "Mean Recall: 0.3876\n",
      "Mean IoU: 0.3566\n",
      "Mean Dice: 0.4970\n"
     ]
    }
   ],
   "source": [
    "# Paths to test images and masks\n",
    "test_img_path = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/data/soiling_woodscape_data/test/droplet_rgb'\n",
    "test_mask_path = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/data/soiling_woodscape_data/test/droplet_masks'\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = UNetWithResNetEncoder(out_channels=1).to(device)\n",
    "model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"WoodScape\")\n",
    "mean_precision, mean_recall, mean_iou, mean_dice = evaluate_model(model, test_img_path, test_mask_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainynuscenes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

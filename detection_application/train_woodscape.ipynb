{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Model (A) - RainyNuScenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train Loss: 0.3916, IoU: 0.0023, Dice: 0.0035\n",
      "Val Loss: 0.3743, IoU: 0.0001, Dice: 0.0001\n",
      "Model improved and saved to /home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth\n",
      "Epoch 2/50\n",
      "Train Loss: 0.4006, IoU: 0.0000, Dice: 0.0000\n",
      "Val Loss: 0.4705, IoU: 0.0000, Dice: 0.0000\n",
      "No improvement in loss for 1 epoch(s).\n",
      "Epoch 3/50\n",
      "Train Loss: 0.3527, IoU: 0.1161, Dice: 0.1678\n",
      "Val Loss: 0.4307, IoU: 0.3812, Dice: 0.5435\n",
      "No improvement in loss for 2 epoch(s).\n",
      "Epoch 4/50\n",
      "Train Loss: 0.3151, IoU: 0.3710, Dice: 0.5163\n",
      "Val Loss: 0.3023, IoU: 0.4936, Dice: 0.6435\n",
      "Model improved and saved to /home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth\n",
      "Epoch 5/50\n",
      "Train Loss: 0.2774, IoU: 0.4886, Dice: 0.6380\n",
      "Val Loss: 0.2767, IoU: 0.5927, Dice: 0.7268\n",
      "Model improved and saved to /home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth\n",
      "Epoch 6/50\n",
      "Train Loss: 0.2447, IoU: 0.5397, Dice: 0.6837\n",
      "Val Loss: 0.2432, IoU: 0.6071, Dice: 0.7432\n",
      "Model improved and saved to /home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth\n",
      "Epoch 7/50\n",
      "Train Loss: 0.2398, IoU: 0.5662, Dice: 0.7076\n",
      "Val Loss: 0.2789, IoU: 0.5366, Dice: 0.6665\n",
      "No improvement in loss for 1 epoch(s).\n",
      "Epoch 8/50\n",
      "Train Loss: 0.2145, IoU: 0.5816, Dice: 0.7225\n",
      "Val Loss: 0.2032, IoU: 0.6757, Dice: 0.7937\n",
      "Model improved and saved to /home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth\n",
      "Epoch 9/50\n",
      "Train Loss: 0.2030, IoU: 0.6038, Dice: 0.7396\n",
      "Val Loss: 0.1904, IoU: 0.6367, Dice: 0.7703\n",
      "Model improved and saved to /home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth\n",
      "Epoch 10/50\n",
      "Train Loss: 0.1973, IoU: 0.6200, Dice: 0.7538\n",
      "Val Loss: 0.2916, IoU: 0.3536, Dice: 0.4925\n",
      "No improvement in loss for 1 epoch(s).\n",
      "Epoch 11/50\n",
      "Train Loss: 0.1718, IoU: 0.6395, Dice: 0.7701\n",
      "Val Loss: 0.1572, IoU: 0.6943, Dice: 0.8128\n",
      "Model improved and saved to /home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth\n",
      "Epoch 12/50\n",
      "Train Loss: 0.1758, IoU: 0.6344, Dice: 0.7680\n",
      "Val Loss: 0.1522, IoU: 0.6981, Dice: 0.8142\n",
      "Model improved and saved to /home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth\n",
      "Epoch 13/50\n",
      "Train Loss: 0.1589, IoU: 0.6639, Dice: 0.7887\n",
      "Val Loss: 0.1593, IoU: 0.7187, Dice: 0.8290\n",
      "No improvement in loss for 1 epoch(s).\n",
      "Epoch 14/50\n",
      "Train Loss: 0.1450, IoU: 0.6908, Dice: 0.8101\n",
      "Val Loss: 0.3024, IoU: 0.4694, Dice: 0.6248\n",
      "No improvement in loss for 2 epoch(s).\n",
      "Epoch 15/50\n",
      "Train Loss: 0.1974, IoU: 0.6263, Dice: 0.7585\n",
      "Val Loss: 0.1799, IoU: 0.6923, Dice: 0.8094\n",
      "No improvement in loss for 3 epoch(s).\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define U-Net Model with Pretrained ResNet Encoder\n",
    "class UNetWithResNetEncoder(nn.Module):\n",
    "    def __init__(self, out_channels=1):\n",
    "        super(UNetWithResNetEncoder, self).__init__()\n",
    "\n",
    "        # Pretrained ResNet backbone\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "\n",
    "        # Encoder layers from ResNet\n",
    "        self.enc1 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu)  # First conv block\n",
    "        self.enc2 = nn.Sequential(resnet.layer1)  # ResNet layer 1\n",
    "        self.enc3 = nn.Sequential(resnet.layer2)  # ResNet layer 2\n",
    "        self.enc4 = nn.Sequential(resnet.layer3)  # ResNet layer 3\n",
    "        self.enc5 = nn.Sequential(resnet.layer4)  # ResNet layer 4\n",
    "\n",
    "        # Decoder layers\n",
    "        def up_conv(in_channels, out_channels):\n",
    "            return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            return block\n",
    "\n",
    "        self.upconv4 = up_conv(512, 256)\n",
    "        self.dec4 = conv_block(512, 256)\n",
    "\n",
    "        self.upconv3 = up_conv(256, 128)\n",
    "        self.dec3 = conv_block(256, 128)\n",
    "\n",
    "        self.upconv2 = up_conv(128, 64)\n",
    "        self.dec2 = conv_block(128, 64)\n",
    "\n",
    "        self.upconv1 = up_conv(64, 64)\n",
    "        self.dec1 = conv_block(64 + 64, 64)\n",
    "\n",
    "        # Output layer\n",
    "        self.conv_last = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        enc5 = self.enc5(enc4)\n",
    "\n",
    "        # Decoder\n",
    "        dec4 = self.upconv4(enc5)\n",
    "        dec4 = torch.cat((dec4, self._align_tensor(enc4, dec4)), dim=1)\n",
    "        dec4 = self.dec4(dec4)\n",
    "\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, self._align_tensor(enc3, dec3)), dim=1)\n",
    "        dec3 = self.dec3(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, self._align_tensor(enc2, dec2)), dim=1)\n",
    "        dec2 = self.dec2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, self._align_tensor(enc1, dec1)), dim=1)\n",
    "        dec1 = self.dec1(dec1)\n",
    "\n",
    "        return torch.sigmoid(self.conv_last(dec1))\n",
    "\n",
    "    def _align_tensor(self, enc, dec):\n",
    "        \"\"\"Align encoder tensor to match the size of the decoder tensor.\"\"\"\n",
    "        enc_h, enc_w = enc.size(2), enc.size(3)\n",
    "        dec_h, dec_w = dec.size(2), dec.size(3)\n",
    "\n",
    "        if enc_h != dec_h or enc_w != dec_w:\n",
    "            enc = nn.functional.interpolate(enc, size=(dec_h, dec_w), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return enc\n",
    "\n",
    "# Define the custom Dataset class\n",
    "class CombinedSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_names = os.listdir(image_dir)\n",
    "        self.mask_names = os.listdir(mask_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Ensure images and masks are aligned by name\n",
    "        self.image_names.sort()\n",
    "        self.mask_names.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_names[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_names[idx])\n",
    "\n",
    "        # Load the image and mask\n",
    "        image = Image.open(image_path).convert('RGB')  # Convert to RGB\n",
    "        mask = Image.open(mask_path).convert('L')  # Binary mask in grayscale\n",
    "\n",
    "        if self.transform is not None:\n",
    "            # Apply transformations to the image only\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert mask to tensor and normalize to 0 and 1\n",
    "        mask = transforms.ToTensor()(mask)\n",
    "        mask = torch.where(mask > 0, torch.tensor(1.0), torch.tensor(0.0))\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# IoU and Dice coefficient functions\n",
    "def calculate_iou(pred, target):\n",
    "    intersection = torch.sum(pred * target)\n",
    "    union = torch.sum(pred) + torch.sum(target) - intersection\n",
    "    return (intersection + 1e-6) / (union + 1e-6)\n",
    "\n",
    "def calculate_dice(pred, target):\n",
    "    intersection = torch.sum(pred * target)\n",
    "    return (2 * intersection + 1e-6) / (torch.sum(pred) + torch.sum(target) + 1e-6)\n",
    "\n",
    "# Validation loop\n",
    "def validate_unet(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    iou_total = 0.0\n",
    "    dice_total = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            outputs = torch.where(outputs > 0.5, torch.tensor(1.0).to(device), torch.tensor(0.0).to(device))\n",
    "\n",
    "            iou_total += calculate_iou(outputs, masks).item()\n",
    "            dice_total += calculate_dice(outputs, masks).item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_iou = iou_total / len(dataloader)\n",
    "    epoch_dice = dice_total / len(dataloader)\n",
    "\n",
    "    return epoch_loss, epoch_iou, epoch_dice\n",
    "\n",
    "# Training loop with CSV logging\n",
    "def train_unet(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, save_path, csv_path):\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Prepare CSV file\n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Epoch', 'Train_Loss', 'Train_IoU', 'Train_Dice', 'Val_Loss', 'Val_IoU', 'Val_Dice'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        running_loss = 0.0\n",
    "        iou_total = 0.0\n",
    "        dice_total = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for images, masks in train_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            outputs = torch.where(outputs > 0.5, torch.tensor(1.0).to(device), torch.tensor(0.0).to(device))\n",
    "\n",
    "            iou_total += calculate_iou(outputs, masks).item()\n",
    "            dice_total += calculate_dice(outputs, masks).item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_iou = iou_total / len(train_loader)\n",
    "        train_dice = dice_total / len(train_loader)\n",
    "\n",
    "        val_loss, val_iou, val_dice = validate_unet(model, val_loader, criterion)\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f}, IoU: {train_iou:.4f}, Dice: {train_dice:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, IoU: {val_iou:.4f}, Dice: {val_dice:.4f}')\n",
    "\n",
    "        # Save metrics to CSV\n",
    "        with open(csv_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch + 1, train_loss, train_iou, train_dice, val_loss, val_iou, val_dice])\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model improved and saved to {save_path}\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement in loss for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "patience = 3\n",
    "save_path = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_model.pth'\n",
    "csv_path = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/detection_application/results/woodscape_metrics.csv'\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),  # Scales image to [0, 1]\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize for RGB\n",
    "])\n",
    "\n",
    "# Dataset and Dataloaders\n",
    "img_train_dir = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/data/soiling_woodscape_data/train/droplet_rgb'\n",
    "mask_train_dir = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/data/soiling_woodscape_data/train/droplet_masks'\n",
    "img_val_dir = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/data/soiling_woodscape_data/val/droplet_rgb'\n",
    "mask_val_dir = '/home/tim/Documents/06_Projekt_RainyNuScenes/rainynuscenes/data/soiling_woodscape_data/val/droplet_masks'\n",
    "\n",
    "dataset_train = CombinedSegmentationDataset(img_train_dir, mask_train_dir, transform=transform)\n",
    "dataset_val = CombinedSegmentationDataset(img_val_dir, mask_val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = UNetWithResNetEncoder(out_channels=1).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_unet(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, save_path, csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainynuscenes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
